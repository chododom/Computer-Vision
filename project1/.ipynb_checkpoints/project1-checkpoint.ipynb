{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC483 Project 1: Intro to Images\n",
    "## OpenCV, matplotlib and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this assignment is to get you familiar with some rudimentary image processing techniques, beginning with parsing an image file and ending with pixel-level operations.   In the process you'll gain some experience with the following:\n",
    "\n",
    "* using gitlab and git\n",
    "* using jupyter notebooks\n",
    "* manipulating numpy arrays\n",
    "* the basics of image formats\n",
    "* greyscale conversion\n",
    "* thresholding\n",
    "* histogram generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Setup\n",
    "\n",
    "You'll need jupyter notebooks, openCV and numpy installed for this project.  All of this software should be installed on CS department machines, but you'll have to undertake your own journey if you choose to install it on your personal machine.  Use slack as a resource!\n",
    "\n",
    "You'll be writing the bulk of your code in *project1.py*, and testing it inside of this notebook.  I've written placeholder stubs for many, but not all of the functions you'll need. The nice thing about this assignment is that you'll know things work if they look good (mostly, at least).\n",
    "\n",
    "I will have given you a brief jupyter notebook tutorial, and we'll be doing some hands-on work in Olin 107 this Thursday.  \n",
    "\n",
    "*** Warning ***: this will be a challenging assignment, don't procrastinate!\n",
    "\n",
    "* Clone the csc483 repo, as instructed by nexus\n",
    "* Create your own (separate) csc483 project, named csc483-username, and clone it into an empty directory\n",
    "* copy the project-1 directory from the class repo into your personal repo, as well as the images directory\n",
    "    * be sure to add, commit, and push the new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you'll need to re-run this cell every time you change your project 1 file\n",
    "from project1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1:  Load a ppm file\n",
    "\n",
    "The netbpm portable pixel format (ppm) is a venerable graphics extenstion.  We'll be using it for this assignment because (a) it is uncompressed and (b) it is ascii format.  You can find descriptions of the file format online.  \n",
    "\n",
    "Start by looking at  *zebra.ascii.ppm* with a plan text editor (typing \"top zebra.ascii.ppm\" from the terminal should suffice).  What does it look like?\n",
    "\n",
    "Finish writing loadppm(), starter code of which is defined in *project1.py*\n",
    "\n",
    "Restrictions:\n",
    "* you must write the parser from scratch!\n",
    "* specifically: you may not use OpenCV or PIL no parse the file\n",
    "* you'll need to learn a bit about numpy arrays, how to create them.\n",
    "\n",
    "Hints:\n",
    "* pixel values should range from 0..255.  When loading them into an nparray, you should be sure to set the data type as 'uint8'.  \n",
    "* you may find the numpy.dstack() function very useful!\n",
    "\n",
    "Testing:\n",
    "* Run the test code below.  It should show two rows of colors.  The first row should contain RED, GREEN, BLUE (left to right).  The second row should contain YELLOW, WHITE, BLACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([], <a list of 0 Text xticklabel objects>),\n",
       " ([], <a list of 0 Text yticklabel objects>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "    rgb = loadppm(\"../images/simple.ascii.ppm\")\n",
    "    plt.xticks([]), plt.yticks([])   # to hide tick values on X and Y axis\n",
    "   \n",
    "    # uncomment the lines below to test\n",
    "    #plt.imshow(rgb)\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this should correclty load a zebra.  Well, a picture of a zebra at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([], <a list of 0 Text xticklabel objects>),\n",
       " ([], <a list of 0 Text yticklabel objects>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAAw9JREFUeJzt1rFNA1EQRdH9iBLsmO2/FrsIx9DD0IHtRbLginPiF0xypVkzswEtb799AHCccCFIuBAkXAgSLgQJF4KEC0HChSDhQtD7kfHpdJp93190CnC9Xr9m5vxodyjcfd+3y+Xy86uAu9Zat2d2XmUIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhaM3M8+O1Prdtu73uHPj3Pmbm/Gh0KFzgb/AqQ5BwIUi4ECRcCBIuBAkXgoQLQcKFIOFC0Dc5dBt9h/mKSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rgb = loadppm(\"../images/zebra.ascii.ppm\")\n",
    "plt.xticks([]), plt.yticks([])   # to hide tick values on X and Y axis\n",
    "\n",
    "#uncomment below to test\n",
    "#plt.imshow(rgb)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Separating Colors\n",
    "\n",
    "Now I want you to implement functions to just separate the red, green, and blue channels out of the image.  \n",
    "\n",
    "Hint: You may want to use the np.split() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = loadppm(\"../images/simple.ascii.ppm\")\n",
    "green = GetGreenPixels(rgb)\n",
    "\n",
    "#you know the routine\n",
    "#plt.xticks([]), plt.yticks([])   # to hide tick values on X and Y axis\n",
    "#plt.imshow(green,cmap='gray', vmin=0, vmax=255)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = GetRedPixels(rgb)\n",
    "#plt.xticks([]), plt.yticks([])   # to hide tick values on X and Y axis\n",
    "#plt.imshow(red,cmap='gray', vmin=0, vmax=255)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = GetBluePixels(rgb)\n",
    "#plt.xticks([]), plt.yticks([])   # to hide tick values on X and Y axis\n",
    "#plt.imshow(green,cmap='gray', vmin=0, vmax=255)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Converting to Greyscale (naive)\n",
    "\n",
    "Next up, create a greyscale image by averaging the red, green, and blue pixel values of the image together to create a single \"flat\" 2D image.  Note that you'll have to normalize the final values to the range 0..255.  Test your function on the same images as above.  Note that there are much \"better\" ways of converting to greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to test greyscale conversions of the colored boxes and the zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Thresholding\n",
    "\n",
    "Now, starting with your greyscale image, us a simple thresholding algorithm to convert to a monochrome black/white image.  For starters, use values < 128 as black, and those >= 128 as white.  Play around with a couple of values, test and display below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to create black/white monochrome image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Histogram Generation and Normalization \n",
    "\n",
    "Following Section 3.1.4 of the textbook, and Thursday's lecture notes, write and test code to do the following for the greyscale zebra image:\n",
    "\n",
    "* calculate the histogram of the greyscale image\n",
    "* calculate the cumulative distribution c(I) of the histogram values\n",
    "* rescale the greyscale values accordingly \n",
    "\n",
    "Display your image below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6:  Bonus\n",
    "\n",
    "Take a look at the checkerboard ppm provided in the images directory.  Using your tools (and any new ones), tell me what color the boxes labeled A and B are, and find a way to process the image to make this more clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Ideas:\n",
    "\n",
    "* Normalize Each Color Channel, rather than the Greyscale\n",
    "* Create a greyscale conversion function that weights colors more realistically.\n",
    "* Ask John for some Satellite Images of the Amazon, and see if you can make a rudimentary measure of the amount of leaf cover in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
